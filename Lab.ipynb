{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56c9f09-e654-42de-9c21-8c680524569e",
   "metadata": {},
   "source": [
    "<center><h1>Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237db658-df92-43ef-b779-940ac77ae89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape # usage : print(mape(pred, observed))\n",
    "\n",
    "import datetime\n",
    "\n",
    "path = 'C:/Users/sebir/Desktop/M2 Toulouse/Défi IA/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98271f11-6ff4-4aee-bd05-277134c6fc7c",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2533486-de74-4d70-aebf-b4aa5f585068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set, X\n",
    "X = pd.read_csv(path + 'X_station_train.csv',\n",
    "                parse_dates=['date'],\n",
    "                infer_datetime_format=True)\n",
    "X.columns = ['number_sta', 'date', 'wind_speed', 'temperature', 'dew_point_temperature', 'humidity', 'wind_direction', 'precipitation', 'Id']\n",
    "\n",
    "X_agg_filledNA = pd.read_csv(path + 'our_X_agg_filled_nearestNeighbours.csv',\n",
    "                             parse_dates=['day'],\n",
    "                             infer_datetime_format=True)\n",
    "\n",
    "# Training set, Y\n",
    "Y = pd.read_csv(path + 'Y_train.csv',\n",
    "                parse_dates=['date'],\n",
    "                infer_datetime_format=True)\n",
    "\n",
    "Y_filledwithNA = pd.read_csv(path + 'Y_train.csv',\n",
    "                parse_dates=['date'],\n",
    "                infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3dae72-2378-4cba-b0c5-1ee7471f060f",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3eccd-a33d-4873-87a5-f1830fcd4423",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `X` hourly to `X_agg`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5874fad-7fdc-4ec5-a03a-2fcbbe2fa817",
   "metadata": {},
   "source": [
    "We have to group the data by data in order to have something comparable with `Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f73906-a159-476e-8645-1352c286a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['day'] = X['date'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51217fe-31fb-42f0-8327-24ae14a391c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg = X.copy()\n",
    "X_agg = X_agg.groupby(by = ['day', 'number_sta'], as_index = False).agg({\n",
    "    \"number_sta\"            : \"first\",\n",
    "    \"wind_speed\"            : \"median\",\n",
    "    \"temperature\"           : \"median\",\n",
    "    \"dew_point_temperature\" : \"median\",\n",
    "    \"humidity\"              : \"median\",\n",
    "    \"wind_direction\"        : \"median\",\n",
    "    \"precipitation\"         : \"sum\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c251a-562c-4f0e-884a-1ba623178930",
   "metadata": {},
   "source": [
    "We firstly drop all the NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d033058-8afc-4fed-93b7-cde4bce30fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg.dropna(inplace = True)\n",
    "Y = Y.loc[X_agg.index]\n",
    "\n",
    "Y.dropna(inplace = True)\n",
    "X_agg = X_agg.loc[Y.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02207b6f-850c-4b70-adca-c9783a244e6d",
   "metadata": {},
   "source": [
    "Adding the month before deleting the date, since we have this information in `X_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c475ebb-e94b-4cb3-a887-8a1d547ddbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg['month'] = X_agg['day'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa57c4-c7be-438a-aefd-010c64ec91d6",
   "metadata": {},
   "source": [
    "We then delete the Id in `Y` which won't be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267c832d-f110-4293-8a6c-05d3078b17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg.drop(['day'], axis = 1, inplace = True)\n",
    "Y.drop(['date', 'Id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5cdacd-ae7e-4122-9add-5ab0e7117d41",
   "metadata": {},
   "source": [
    "## `X_agg_filledNA`\n",
    "We took `X_agg` and we filled the gaps with data from nearests neighbours. Preprocessing data for coherence with `Y`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75363ecd-0c90-4216-8ef0-e8a2dcf0f8ce",
   "metadata": {},
   "source": [
    "Adding the month before deleting the date, since we have this information in `X_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8920b4-28b1-4ea0-a313-c26fdad30d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_agg_filledNA['month'] = X_agg_filledNA['day'].apply(lambda x: x.month)\n",
    "X_agg_filledNA.drop('day', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b3aeb4-1ff0-4074-8d16-da4996b05872",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_filledwithNA.dropna(inplace = True)\n",
    "X_agg_filledNA = X_agg_filledNA.loc[Y_filledwithNA.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a3ada-613e-43fb-b73d-16e423e62c52",
   "metadata": {},
   "source": [
    "## `our_X_filled_nearestNeighbours` to `X_filled_agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "895e6d11-69bf-4384-81f7-22766fea4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled = pd.read_csv(path + 'our_X_filled_nearestNeighbours.csv',\n",
    "                       parse_dates=['date'],\n",
    "                       infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60de657e-00ed-4be0-a631-336742d321ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_filled = pd.read_csv(path + 'Y_train.csv',\n",
    "                       parse_dates=['date'],\n",
    "                       infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bea0a5d5-6d77-4941-8c46-f1deb90d9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled['day'] = X_filled['date'].apply(lambda x: x.date())\n",
    "\n",
    "X_filled_agg = X_filled.copy()\n",
    "X_filled_agg = X_filled_agg.groupby(by = ['day', 'number_sta'], as_index = False).agg({\n",
    "    \"number_sta\"            : \"first\",\n",
    "    \"wind_speed\"            : \"median\",\n",
    "    \"temperature\"           : \"median\",\n",
    "    \"dew_point_temperature\" : \"median\",\n",
    "    \"humidity\"              : \"median\",\n",
    "    \"wind_direction\"        : \"median\",\n",
    "    \"precipitation\"         : \"sum\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ddedfd6-f4cd-4c77-846a-ec9d53d8d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled_agg.dropna(inplace = True)\n",
    "Y_filled = Y_filled.loc[X_filled_agg.index]\n",
    "\n",
    "Y_filled.dropna(inplace = True)\n",
    "X_filled_agg = X_filled_agg.loc[Y_filled.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "166f7874-e4d2-4783-85de-23c090377d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled_agg['month'] = X_filled_agg['day'].apply(lambda x: x.month)\n",
    "\n",
    "X_filled_agg.drop(['day'], axis = 1, inplace = True)\n",
    "Y_filled.drop(['date', 'Id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b91a73-49f8-421a-b04e-ae801af293ab",
   "metadata": {},
   "source": [
    "# Trial with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6562bead-ca90-4822-9d68-10b2fdf6e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9abf9a8f-d26f-4e0f-9363-a8eb2dc1c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler(with_mean=True)\n",
    "\n",
    "X_agg_scale = sc.fit_transform(X_agg)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "sc = StandardScaler(with_mean=True)\n",
    "\n",
    "X_agg_filledNA_scale = sc.fit_transform(X_agg_filledNA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ae1d3-fa43-4470-9bc2-d8caf51e7b27",
   "metadata": {},
   "source": [
    "Trying to drop all nas (84943 rows available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bda8093-dd97-4913-9373-995ba6442f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with dropping NAs: 1.2088862054578846\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_agg_scale, Y['Ground_truth'], test_size = 0.3)\n",
    "rf = RandomForestRegressor(n_estimators = 200)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(f\"Score with dropping NAs: {mape(y_predict, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a420f3-969d-416c-8a56-e1bb070bda71",
   "metadata": {},
   "source": [
    "Trying with filling the NAs with nearest neighbour's values (183747 rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd1cae8b-4f8f-4e9f-a1aa-8d8ee800d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with dropping NAs: 1.118526846948131\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_agg_filledNA_scale, Y_filledwithNA['Ground_truth'], test_size = 0.3)\n",
    "rf = RandomForestRegressor(n_estimators = 200)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(f\"Score with dropping NAs: {mape(y_predict, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047840d0-f0ba-4e05-9881-1a314bca5cbb",
   "metadata": {},
   "source": [
    "Trying with aggregating after filling the NAs with nearest neighbour's values (162107 rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "107436f1-2f03-4b24-9f44-acc7150fcd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler(with_mean=True)\n",
    "\n",
    "X_filled_agg_scale = sc.fit_transform(X_filled_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd425543-39ef-48d1-b7ba-df1d9590a938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with dropping NAs: 37041511956.97175\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_filled_agg, Y_filled['Ground_truth'], test_size = 0.3)\n",
    "rf = RandomForestRegressor(n_estimators = 200)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(f\"Score with dropping NAs: {mape(y_predict, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8246a-e58b-4b2a-ab97-97ca211a153b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trying to improve the RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40e7c7-c8e8-4be0-80a8-641168c32461",
   "metadata": {},
   "source": [
    "We can try to first perform a scaler before doing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd515d-823c-4976-bb42-63d358a2be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X_scaled = scale(X_agg.drop('number_sta', axis = 1)) # centralisation et normalisation\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = X_agg.drop('number_sta', axis = 1).columns)\n",
    "X_scaled['number_sta'] = X_agg['number_sta'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711afca-1979-48b7-9c79-936d6baf10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y['Ground_truth'], test_size = 0.3)\n",
    "rf_scaled = RandomForestRegressor(n_estimators = 200)\n",
    "rf_scaled.fit(X_train, y_train)\n",
    "y_predict = rf_scaled.predict(X_test)\n",
    "print(f\"Score: {mape(y_predict, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287279c-e9da-402c-8636-9ae692abbe01",
   "metadata": {},
   "source": [
    "We can try to fit and learn several times with different parameters to see if it gives better results. Things to try:\n",
    "* whether scaling gives better result or not (perform a few ones for scaled and non-scaled data, then see distribution). We can also fit the models on the same scaled and non-scaled dataset, using `random_state = xx` of `train_test_split`, to compare.\n",
    "* the importance of `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6c6a5-875b-4cf6-8dbc-cf54a6f3980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "# Performing the scaling once\n",
    "X_scaled = scale(X_agg.drop('number_sta', axis = 1)) # centralisation et normalisation\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = X_agg.drop('number_sta', axis = 1).columns)\n",
    "X_scaled['number_sta'] = X_agg['number_sta'].to_list()\n",
    "\n",
    "\n",
    "nbTrials = 15\n",
    "\n",
    "# Without scaling\n",
    "scores_without_scaling = []\n",
    "for i in trange(nbTrials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_agg, Y['Ground_truth'], test_size = 0.3)\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_predict = rf.predict(X_test)\n",
    "    scores_without_scaling.append(mape(y_predict, y_test))\n",
    "\n",
    "# With scaling\n",
    "scores_with_scaling = []\n",
    "for i in trange(nbTrials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y['Ground_truth'], test_size = 0.3)\n",
    "    rf_scaled = RandomForestRegressor()\n",
    "    rf_scaled.fit(X_train, y_train)\n",
    "    y_predict = rf_scaled.predict(X_test)\n",
    "    scores_with_scaling.append(mape(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f1b72-9a70-488e-81a8-00bbcf1cdd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Without scaler:\")\n",
    "print(f\"{(np.array(scores_without_scaling) < 10).sum()}/15 converged\")\n",
    "print(f\"Mean of MAPE score = {np.array(scores_without_scaling)[np.array(scores_without_scaling) < 10].mean()}\")\n",
    "\n",
    "print(\"With scaler:\")\n",
    "print(f\"{(np.array(scores_with_scaling) < 10).sum()}/15 converged\")\n",
    "print(f\"Mean of MAPE score = {np.array(scores_with_scaling)[np.array(scores_with_scaling) < 10].mean()}\")\n",
    "\n",
    "# print(\"Mean with scaler:\")\n",
    "# np.array(scores_without_scaling)[np.array(scores_without_scaling) < 10].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051354b-b9e6-47f1-8550-50cf5dcdaba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Performing the scaling once\n",
    "X_scaled = scale(X_agg.drop('number_sta', axis = 1)) # centralisation et normalisation\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = X_agg.drop('number_sta', axis = 1).columns)\n",
    "X_scaled['number_sta'] = X_agg['number_sta'].to_list()\n",
    "\n",
    "\n",
    "n_estimators = [100, 112, 125, 137, 150, 162, 175, 187, 200, 212, 225, 237, 250, 262, 275, 287, 300]\n",
    "\n",
    "# With scaling\n",
    "scores_estimators = []\n",
    "for n_estimator in tqdm(n_estimators):\n",
    "    print(f\"With {n_estimator} trees:\")\n",
    "    mean = []\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y['Ground_truth'], test_size = 0.3)\n",
    "    rf_scaled = RandomForestRegressor(n_estimators = n_estimator)\n",
    "    rf_scaled.fit(X_train, y_train)\n",
    "    y_predict = rf_scaled.predict(X_test)\n",
    "    score = mape(y_predict, y_test)\n",
    "\n",
    "    while score > 1000:\n",
    "        print(\"Score was > 1000\")\n",
    "        # If diverged, run again until we get convergence\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y['Ground_truth'], test_size = 0.3)\n",
    "        rf_scaled = RandomForestRegressor(n_estimators = n_estimator)\n",
    "        rf_scaled.fit(X_train, y_train)\n",
    "        y_predict = rf_scaled.predict(X_test)\n",
    "        score = mape(y_predict, y_test)\n",
    "            \n",
    "    print(\"Converged\")\n",
    "    \n",
    "    scores_estimators.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d8453-23f8-424d-87b3-5ad91967ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(n_estimators, scores_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847796a-d04c-4f3c-b66b-6f5a5185afe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e7e74d1-edce-4c01-b1d2-c9fc1c126980",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "954e8e63-61aa-41e7-812f-fbad9ca6be32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dd</th>\n",
       "      <th>hu</th>\n",
       "      <th>td</th>\n",
       "      <th>t</th>\n",
       "      <th>ff</th>\n",
       "      <th>precip</th>\n",
       "      <th>month</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>14047002_277_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>14047002_277_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>14047002_277_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>14047002_277_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>14047002_277_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304797</th>\n",
       "      <td>190.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>277.00</td>\n",
       "      <td>279.74</td>\n",
       "      <td>10.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>95690001_176_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304798</th>\n",
       "      <td>195.0</td>\n",
       "      <td>84.2</td>\n",
       "      <td>277.44</td>\n",
       "      <td>279.93</td>\n",
       "      <td>11.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>95690001_176_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304799</th>\n",
       "      <td>199.0</td>\n",
       "      <td>85.7</td>\n",
       "      <td>277.95</td>\n",
       "      <td>280.21</td>\n",
       "      <td>11.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>95690001_176_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304800</th>\n",
       "      <td>198.0</td>\n",
       "      <td>85.3</td>\n",
       "      <td>278.25</td>\n",
       "      <td>280.58</td>\n",
       "      <td>10.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>95690001_176_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304801</th>\n",
       "      <td>190.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>278.60</td>\n",
       "      <td>280.80</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>95690001_176_23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2304802 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dd    hu      td       t     ff  precip  month               Id\n",
       "0          NaN   NaN     NaN  278.35    NaN     NaN     12   14047002_277_4\n",
       "1          NaN   NaN     NaN  278.40    NaN     0.0     12   14047002_277_5\n",
       "2          NaN   NaN     NaN  279.01    NaN     0.0     12   14047002_277_6\n",
       "3          NaN   NaN     NaN  279.66    NaN     0.0     12   14047002_277_7\n",
       "4          NaN   NaN     NaN  279.99    NaN     0.0     12   14047002_277_8\n",
       "...        ...   ...     ...     ...    ...     ...    ...              ...\n",
       "2304797  190.0  82.8  277.00  279.74  10.62     0.0     12  95690001_176_19\n",
       "2304798  195.0  84.2  277.44  279.93  11.86     0.0     12  95690001_176_20\n",
       "2304799  199.0  85.7  277.95  280.21  11.77     0.0     12  95690001_176_21\n",
       "2304800  198.0  85.3  278.25  280.58  10.16     0.0     12  95690001_176_22\n",
       "2304801  190.0  86.0  278.60  280.80   9.50     0.0     12  95690001_176_23\n",
       "\n",
       "[2304802 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(path + 'X_station_test.csv')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab275cb6-3105-441b-af6f-dc0afb0d0a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
